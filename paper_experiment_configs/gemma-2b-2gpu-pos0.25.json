{
    "deepspeed": "configs/state1.json",
    "model_name": "google/gemma-2-2b-it",
    "per_device_train_batch_size": 16,
    "per_device_eval_batch_size": 16,
    "gradient_accumulation_steps": 4,
    "learning_rate": 5e-6,
    "weight_decay": 1e-3,
    "bf16": true,
    "num_train_epochs": 2,
    "output_path": "./bt_models",
    "gradient_checkpointing": true,
    "optim": "paged_adamw_32bit",
    "lr_scheduler_type": "cosine",
    "max_length": 2048,
    "save_every_steps": 999999,
    "eval_every_steps": 64,
    "use_lora": false,
    "trainer_type": "oraclece",
    "label_type": "interpolated",
    "train_set_path": "statdata/prefer_skywork_Skywork/Skywork-Reward-Gemma-2-27B-v0.2",
    "seed": 42,
    "diff_rescaling_factor": 0.15,
    "warmup_ratio": 0.05,
    "selected_pos_ratio": 0.25
}